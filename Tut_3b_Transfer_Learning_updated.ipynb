{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6x62xMrvYsy"
      },
      "source": [
        "## Tutorial 3b - Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJzuvfXc1L1F"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhtkZ4Rif9n1"
      },
      "source": [
        "Typically we do not train an entire Convolutional Neural Networks from scratch. One reason is that it is rare to have access to enough data to train the networks sufficiently. The other reason, as we have seen in labs 2 and 3, training neural networks can take a long time even on small 32 x 32 pixel images. Extending this to larger images such as the 3 x 224 x 224 that are commonly found in the ImageNet dataset could take weeks on a single GPUs.\n",
        "\n",
        "Instead, we can use pretrained networks such as the AlexNet, or VGG as feature extractors and train a smaller fully connected ANN to do our final classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3kvkiqM8JZM"
      },
      "source": [
        "## AlexNet in PyTorch\n",
        "\n",
        "Convolutional networks are very commonly used, meaning that there are often alternatives to\n",
        "training convolutional networks from scratch. In particular, researchers often release both\n",
        "the architecture and **the weights** of the networks they train.\n",
        "\n",
        "As an example, let's look at the AlexNet model, whose trained weights are included in `torchvision`.\n",
        "AlexNet was trained to classify images into one of many categories.\n",
        "The AlexNet can be imported and used as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PB5GXM4WoZ"
      },
      "source": [
        "# alexnet\n",
        "import torchvision.models\n",
        "\n",
        "alexNet = torchvision.models.alexnet(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV_nPb5cy2DW"
      },
      "source": [
        "alexNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnteiMhJyzcq"
      },
      "source": [
        "Notice that the AlexNet model is split into two parts. There is a component that computes\n",
        "\"features\" using convolutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ7cd1poyzcr"
      },
      "source": [
        "alexNet.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4VnMUdqyzcu"
      },
      "source": [
        "There is also a component that classifies the image based on the computed features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82TDZSDDyzcu"
      },
      "source": [
        "alexNet.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiB-o0ls8bj5"
      },
      "source": [
        "### AlexNet Features\n",
        "\n",
        "The first network can be used independently of the second. Specifically, it can be used\n",
        "to compute a set of **features** that can be used later on. This idea of using neural\n",
        "network activation *features* to represent images is an extremely important one, so it\n",
        "is important to understand the idea now.\n",
        "\n",
        "To see how we can do this, let's first load an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxlJlLZZ_-9j"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import urllib\n",
        "\n",
        "#load colour image\n",
        "url =\"https://drive.google.com/uc?export=view&id=1oaLVR2hr1_qzpKQ47i9rVUIklwbDcews\"\n",
        "img = np.array(PIL.Image.open(urllib.request.urlopen(url)))\n",
        "\n",
        "img = img[:,:,:3]\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVds1tCxOs9d"
      },
      "source": [
        "To use this image we need to convert it into a PyTorch tensor of the appropriate shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VifTUQkJNbq7"
      },
      "source": [
        "import torch\n",
        "\n",
        "#convert to tensor\n",
        "x = torch.from_numpy(img) # turn img into a PyTorch tensor\n",
        "print(x.shape)\n",
        "\n",
        "x = x.permute(2,0,1)      # move the channel dimension to the beginning\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RVGrS7ZljsC"
      },
      "source": [
        "Next, we feed the image x as an input to our alexNet feature network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUeeiowNyzcx"
      },
      "source": [
        "import torch\n",
        "\n",
        "#features = alexNet.features(x)\n",
        "#features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZZv-ZxhyzcK"
      },
      "source": [
        "**This results in an error!** Even when our batch size is 1, we still need the batch size dimension to be set to 1, so that the input\n",
        "follows the \"NCHW\" format (N = batch size, C = channels, H = height, W = width)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LusiTJoPR8v"
      },
      "source": [
        "x = x.reshape([1, 3, 350, 210]) # add a dimension for batching\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_T3Yr-wPXG5"
      },
      "source": [
        "import torch\n",
        "x = x.float()\n",
        "\n",
        "features = alexNet.features(x)\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHovTaIfyzc0"
      },
      "source": [
        "The set of numbers in `features` is another way of representing our image `x`. Recall that\n",
        "our initial image `x` was also represented as a tensor, also a set of numbers representing\n",
        "pixel intensity. Geometrically speaking, we are using points in a high-dimensional space to\n",
        "represent the images. in our pixel representation, the axes in this high-dimensional space\n",
        "were different pixels. In our `features` representation, the axes are not as easily\n",
        "interpretable.\n",
        "\n",
        "But we will want to work with the `features` representation, because this representation\n",
        "makes classification easier. This representation organizes images in a more \"useful\" and\n",
        "\"semantic\" way than pixels.\n",
        "\n",
        "Let me be more specific:\n",
        "this set of `features` was trained on image classification. It turns out that\n",
        "**these features can be useful for performing other image-related tasks as well!**\n",
        "That is, if we want to perform an image classification task of our own (for example,\n",
        "classifying cancer biopsies, which is nothing like what AlexNet was trained to do),\n",
        "we might compute these AlexNet features, and then train a small model on top of those\n",
        "features. We replace the `classifier` portion of `AlexNet`, but keep its `features`\n",
        "portion intact.\n",
        "\n",
        "Somehow, through being trained on one type of image classification problem, AlexNet\n",
        "learned something general about representing images for the purposes of other\n",
        "classification tasks.\n",
        "\n",
        "### AlexNet First Convolutions\n",
        "\n",
        "Here is the first convolution of AlexNet, applied to our image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYaQrQNgyzc1"
      },
      "source": [
        "alexNetConv = alexNet.features[0]\n",
        "y = alexNetConv(x)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqDa2OqDyzc3"
      },
      "source": [
        "The output is a $1 \\times 64 \\times 86 \\times 51$ tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE_CHfptyzc4"
      },
      "source": [
        "y = y.detach().numpy()\n",
        "y = (y - y.min()) / (y.max() - y.min())\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISZEjXzdyzc7"
      },
      "source": [
        "We can visualize each channel independently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTRS4E4-80lt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(64):\n",
        "    plt.subplot(8, 8, i+1)\n",
        "    plt.imshow(y[0, i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBv4bJdP1PM"
      },
      "source": [
        "What happens to the output if we try to use other images? Specifically, what happens to the size of the feature tensor when you use a cat image vs. a dog image? What changes? What stays the same?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdSHb5iGo095"
      },
      "source": [
        "## Applying AlexNet on a Dataset\n",
        "In order to use transfer learning with AlexNet on a new dataset we will have to keep in mind how AlexNet was trained. AlexNet was trained on images of 3 x 224 x 224 images from the ImageNet dataset. These images are of higher resolution than what we have seen until now and are in colour. Hence, it would take significant effort to apply AlexNet to MNIST data, instead we will use another dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnjK6g5z8KcF"
      },
      "source": [
        "### Data Loading from a File\n",
        "To load our data we will use PyTorch's ImageFolder class which makes things a lot easier by allowing you to load data from a directory. For example, the training images are all stored in a directory path that looks like this:\n",
        "\n",
        "/datadir\n",
        "\n",
        "    /train  \n",
        "        /class1  \n",
        "        /class2  \n",
        "        .  \n",
        "        .  \n",
        "    /val  \n",
        "        /class1  \n",
        "        /class2  \n",
        "        .  \n",
        "        .  \n",
        "    /test  \n",
        "        /class1  \n",
        "        /class2  \n",
        "        .  \n",
        "        .  \n",
        "\n",
        "You will need to mount your Google Drive to make this work with Colab.\n",
        "\n",
        "**It is important to copy the dataset in the host's local storage (e.g., unzip in `/root/datasets`)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y-ayhFs3Ex7"
      },
      "source": [
        "# mount our Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp3Uo2CswdFG"
      },
      "source": [
        "# !unzip '/content/drive/My Drive/Colab Notebooks/Flower_Data_Large.zip' -d '/root/datasets'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEmPmac0oLWx"
      },
      "source": [
        "If you have not uploaded the dataset to your google drive use this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br6BSt3VhqkZ"
      },
      "source": [
        "! pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL9UnbBAhubo"
      },
      "source": [
        "!wget --no-check-certificate 'https://www.dropbox.com/scl/fi/8dniijwl4nskmfph91mc0/Flower_Data_Large.zip?rlkey=vrnplzh9yest31j775ch8h9ri&st=elbpuhll&dl=1' -O Flower_Data_Large.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBS3nZo9h-Ag"
      },
      "source": [
        "!unzip 'Flower_Data_Large.zip' -d '/root/datasets/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNoTHZHV3XEC"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAjEHdUW6F-I"
      },
      "source": [
        "# define training and test data directories\n",
        "data_dir = '/root/datasets/'\n",
        "train_dir = os.path.join(data_dir, 'train/')\n",
        "val_dir = os.path.join(data_dir, 'val/')\n",
        "\n",
        "# classes are folders in each directory with these names\n",
        "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb_SiFsq6fQC"
      },
      "source": [
        "# load and transform data using ImageFolder\n",
        "\n",
        "# resize all images to 224 x 224\n",
        "data_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "val_data = datasets.ImageFolder(val_dir, transform=data_transform)\n",
        "\n",
        "# print out some data stats\n",
        "print('Num training images: ', len(train_data))\n",
        "print('Num validation images: ', len(val_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jayx4O0S6mZ2"
      },
      "source": [
        "# define dataloader parameters\n",
        "batch_size  = 256\n",
        "num_workers = 0\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size,\n",
        "                                          num_workers=num_workers, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMtRF4LK6n7S"
      },
      "source": [
        "# Visualize some sample data\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymsWSTFb8QBV"
      },
      "source": [
        "### AlexNet Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Ssc83d8UJA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim #for gradient descent\n",
        "\n",
        "# alexnet\n",
        "import torchvision.models\n",
        "\n",
        "torch.manual_seed(1) # set the random seed\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# confirm output from AlexNet feature extraction\n",
        "alexNet = torchvision.models.alexnet(pretrained=True)\n",
        "features = alexNet.features(images)\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWLpmLDB85qw"
      },
      "source": [
        "#Artifical Neural Network Architecture\n",
        "class ANNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 10)\n",
        "        self.fc2 = nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 256 * 6 * 6) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf_EYe2n9CCY"
      },
      "source": [
        "def get_accuracy(model, train=False):\n",
        "    if train:\n",
        "        data_loader = train_loader\n",
        "    else:\n",
        "        data_loader = val_loader\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "\n",
        "\n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "\n",
        "        output = model(ALNC(imgs))\n",
        "\n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLR2qf8N9CN1"
      },
      "source": [
        "def train(model, data, batch_size=20, num_epochs=1):\n",
        "    #train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    # train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           #num_workers=num_workers, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    start_time=time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        mini_b=0\n",
        "        mini_batch_correct = 0\n",
        "        Mini_batch_total = 0\n",
        "        for imgs, labels in iter(train_loader):\n",
        "\n",
        "\n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            #############################################\n",
        "\n",
        "          #### ALNC is alexNet.features (AlexNet without classifier) ####\n",
        "\n",
        "            out = model(ALNC(imgs))             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "\n",
        "\n",
        "            ##### Mini_batch Accuracy ##### We don't compute accuracy on the whole training set in every iteration!\n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "            mini_batch_correct = pred.eq(labels.view_as(pred)).sum().item()\n",
        "            Mini_batch_total = imgs.shape[0]\n",
        "            train_acc.append((mini_batch_correct / Mini_batch_total))\n",
        "           ###########################\n",
        "\n",
        "          # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy\n",
        "            n += 1\n",
        "            mini_b += 1\n",
        "            print(\"Iteration: \",n,'Progress: % 6.2f ' % ((epoch * len(train_loader) + mini_b) / (num_epochs * len(train_loader))*100),'%', \"Time Elapsed: % 6.2f s \" % (time.time()-start_time))\n",
        "\n",
        "\n",
        "        print (\"Epoch %d Finished. \" % epoch ,\"Time per Epoch: % 6.2f s \"% ((time.time()-start_time) / (epoch +1)))\n",
        "\n",
        "\n",
        "    end_time= time.time()\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Training\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    train_acc.append(get_accuracy(model, train=True))\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "    print (\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % ( (end_time-start_time), ((end_time-start_time) / num_epochs) ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsmKoUQfotgM"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ebjisS_9Jxp"
      },
      "source": [
        "use_cuda = True\n",
        "\n",
        "model = ANNClassifier()\n",
        "ALNC = alexNet.features\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  ALNC.cuda()\n",
        "  model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "#proper model\n",
        "train(model, [], batch_size=batch_size, num_epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ184Z5L46ui"
      },
      "source": [
        "The above example is only used to demonstrate the implementation of transfer learning. You are encouraged to explore different set of parameters and ways to improve the speed of the training. Note also that there is a larger dataset of flowers which you may want to try out as well to see if you can improve on the classification accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW0L5cDyR2yd"
      },
      "source": [
        "# Preventing Overfitting\n",
        "\n",
        "In the last few weeks we discussed the idea of **overfitting**,\n",
        "where a neural network model learns about the quirks of the training data,\n",
        "rather than information that is generalizable to the task\n",
        "at hand. We also briefly discussed idea of **underfitting**, but not in as much depth.\n",
        "\n",
        "The reason we did not discuss underfitting much is because nowadays,\n",
        "practitioners tend to avoid underfitting altogether by opting for more\n",
        "powerful models. Since computation is (relatively) cheap,\n",
        "and overfitting is much easier to detect, it is more straightforward\n",
        "to build a high-capacity model and use known techniques to prevent\n",
        "overfitting. So, always start with slightly more *capacity* than you need,\n",
        "then use some of the many strategies to prevent overfitting.\n",
        "\n",
        "We've actually already discussed several strategies for preventing overfitting:\n",
        "\n",
        "- Use a larger training set\n",
        "- Use a smaller network\n",
        "- Weight-sharing (as in convolutional neural networks)\n",
        "- Early stopping\n",
        "- Transfer Learning\n",
        "\n",
        "Some of these are more practical than others. For example, collecting a larger training\n",
        "set may be impractical or expensive in practice. Using a smaller network means that we need\n",
        "to restart training, rather than use what we already know about hyperparameters and appropriate\n",
        "weights.\n",
        "\n",
        "**Early stopping** was introduced in lab 2,\n",
        "where we did not use the trained weights from the last training iteration\n",
        "as our ``final'' model.\n",
        "Instead, we used a model (a set of weights) from a previous\n",
        "iteration of training. We chose the iteration/epoch to use based on\n",
        "the training curve.\n",
        "\n",
        "**Transfer learning** where we use pre-trained weights of a different model (e.g. AlexNet)\n",
        "as part of our neural network also helps prevent overfitting.\n",
        "The architectures and weights of AlexNet was trained using a larger\n",
        "dataset of over a million images, and was trained to solve a different image classification problem.\n",
        "Nevertheless, transfer learning allows us to leverage information\n",
        "from larger data sets with low computational cost. Effectively acting like a larger training set.\n",
        "\n",
        "These are only some of the techniques for preventing overfitting. We'll discuss more techniques today,\n",
        "including:\n",
        "\n",
        "- Data Normalization\n",
        "- Data Augmentation\n",
        "- Weight Decay\n",
        "- Model Averaging\n",
        "- Dropout\n",
        "\n",
        "We will use the MNIST digit recognition problem as a running example. Since we are studying overfitting,\n",
        "I will artificially reduce the number of training examples to 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4X2ososR2ye"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(1)\n",
        "\n",
        "mnist_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_data = list(mnist_data)\n",
        "mnist_train = mnist_data[:200]     #  200 train images\n",
        "mnist_val   = mnist_data[300:2300] # 2000 validation images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIkuBVFFR2yh"
      },
      "source": [
        "We will also use the `MNISTClassifier` from the last few weeks as our base model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsy8aziFR2yi"
      },
      "source": [
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 50)\n",
        "        self.layer2 = nn.Linear(50, 20)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28)\n",
        "        activation1 = F.relu(self.layer1(flattened))\n",
        "        activation2 = F.relu(self.layer2(activation1))\n",
        "        output = self.layer3(activation2)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrNTLq5zR2ym"
      },
      "source": [
        "And of course, our training code, with minor modifications that we will explain as we go along."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty8XWXPfR2yn"
      },
      "source": [
        "def train(model, train, valid, batch_size=20, num_iters=1, learn_rate=0.01, weight_decay=0):\n",
        "    train_loader = torch.utils.data.DataLoader(train,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True) # shuffle after every epoch\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    while True:\n",
        "        if n >= num_iters:\n",
        "            break\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            model.train() #*****************************#\n",
        "            out = model(imgs)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            if n % 10 == 9:\n",
        "                iters.append(n)\n",
        "                losses.append(float(loss)/batch_size)        # compute *average* loss\n",
        "                train_acc.append(get_accuracy(model, train)) # compute training accuracy\n",
        "                val_acc.append(get_accuracy(model, valid))   # compute validation accuracy\n",
        "            n += 1\n",
        "\n",
        "    # plotting\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "\n",
        "\n",
        "train_acc_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100)\n",
        "val_acc_loader = torch.utils.data.DataLoader(mnist_val, batch_size=1000)\n",
        "\n",
        "def get_accuracy(model, data):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval() #*********#\n",
        "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):\n",
        "        output = model(imgs)\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OghffiCRR2yq"
      },
      "source": [
        "Without any intervention, our model gets to about 52-53% accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnNjz_-YR2yr"
      },
      "source": [
        "model = MNISTClassifier()\n",
        "train(model, mnist_train, mnist_val, num_iters=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH0WFu7MR2yv"
      },
      "source": [
        "## Data Normalization\n",
        "\n",
        "*Data normalization* means to scale the input features of a neural\n",
        "network, so that all features are scaled similarly (similar means\n",
        "and standard deviations). Although data normalization does not directly\n",
        "prevent overfitting, normalizing your data makes the training\n",
        "problem easier.\n",
        "\n",
        "Data normalization is less of an issues for input data -- like images --\n",
        "where all input features have similar interpretations.\n",
        "All features of an image are pixel intensities, all of which are scaled\n",
        "the same way. However, if we were performing prediction of, say,\n",
        "housing prices based on a house's number of bedrooms, square footage, etc.,\n",
        "we would want each of the features to be scaled similarly. A scale\n",
        "of mean 0 and standard deviation 1 is one approach. Another approach\n",
        "is to scale each feature so that they are in the range `[0, 1]`.\n",
        "\n",
        "The PyTorch transform `transforms.ToTensor()` automatically scales\n",
        "each pixel intensity to the range `[0, 1]`.\n",
        "In your lab 2 code, we used the following transform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIYqVgi8R2yw"
      },
      "source": [
        "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy1bKRrkR2yy"
      },
      "source": [
        "This transform subtracts 0.5 from each pixel, and divides the\n",
        "result by 0.5. So, each pixel intensity will be in the range `[-1, 1]`.\n",
        "In general, having both positive and negative input values helps\n",
        "the network trains quickly (because of the way weights are initialized).\n",
        "Sticking with each pixel being in the range `[0, 1]` is usually fine.\n",
        "\n",
        "## Data Augmentation\n",
        "\n",
        "While it is often expensive to gather more data, we can often\n",
        "programmatically *generate* more data points from our existing\n",
        "data set. We can make small alterations to our training set to obtain\n",
        "slightly different input data, but that is still valid.\n",
        "Common ways of obtaining new (image) data include:\n",
        "\n",
        "- Flipping each image horizontally or vertically (won't work for digit recognition, but might for other tasks)\n",
        "- Shifting each pixel a little to the left or right\n",
        "- Rotating the images a little\n",
        "- Adding noise to the image\n",
        "\n",
        "... or even a combination of the above. For demonstration purposes, let's randomly\n",
        "rotate our digits a little to get new training samples.\n",
        "\n",
        "Here are the 20 images in our training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_lA2xc2R2yz"
      },
      "source": [
        "def show20(data):\n",
        "    plt.figure(figsize=(10,2))\n",
        "    for n, (img, label) in enumerate(data):\n",
        "        if n >= 20:\n",
        "            break\n",
        "        plt.subplot(2, 10, n+1)\n",
        "        plt.imshow(img)\n",
        "\n",
        "mnist_imgs = datasets.MNIST('data', train=True, download=True)\n",
        "show20(mnist_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxzjX1xaR2y2"
      },
      "source": [
        "Here are the 20 images in our training set, each rotated randomly, by up to 25 degrees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMM2pQouR2y3"
      },
      "source": [
        "mnist_new = datasets.MNIST('data', train=True, download=True,\n",
        "                           transform=transforms.RandomRotation(25))\n",
        "show20(mnist_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpn_-kKZR2y6"
      },
      "source": [
        "If we apply the transformation again, we can get images with different rotations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dJ41UyJR2y7"
      },
      "source": [
        "mnist_new = datasets.MNIST('data', train=True, download=True, transform=transforms.RandomRotation(25))\n",
        "show20(mnist_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xvIXa4tR2y-"
      },
      "source": [
        "We can augment our data set by, say, randomly rotating each training data point 100 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "`"
          ],
          "id": ""
        },
        "id": "jGkCTG2RR2y_"
      },
      "source": [
        "augmented_train_data = []\n",
        "\n",
        "my_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(25),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "for i in range(100):\n",
        "    mnist_new = datasets.MNIST('data', train=True, download=True, transform=my_transform)\n",
        "    for j, item in enumerate(mnist_new):\n",
        "        if j >= 20:\n",
        "            break\n",
        "        augmented_train_data.append(item)\n",
        "\n",
        "len(augmented_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lwSWjm9R2zC"
      },
      "source": [
        "We obtain a better validation accuracy after training on our expanded dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_rtF_wSR2zC"
      },
      "source": [
        "model = MNISTClassifier()\n",
        "train(model, augmented_train_data, mnist_val, num_iters=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LElZnRJ-R2zF"
      },
      "source": [
        "## Weight Decay\n",
        "\n",
        "A more interesting technique that prevents overfitting is the idea of weight decay.\n",
        "The idea is to **penalize large weights**. We avoid large weights, because large weights\n",
        "mean that the prediction relies a lot on the content of one pixel, or on one unit. Intuitively,\n",
        "it does not make sense that the classification of an image should depend heavily on the\n",
        "content of one pixel, or even a few pixels.\n",
        "\n",
        "Mathematically, we penalize large weights by adding an extra term to the loss function,\n",
        "the term can look like the following:\n",
        "\n",
        "- $L^1$ regularization: $\\sum_k |w_k|$\n",
        "    - Mathematically, this term encourages weights to be exactly 0\n",
        "- $L^2$ regularization: $\\sum_k w_k^2$\n",
        "    - Mathematically, in each iteration the weight is pushed towards 0\n",
        "- Combination of $L^1$ and $L^2$ regularization: add a term $\\sum_k |w_k| + w_k^2$  to the loss function.\n",
        "\n",
        "In PyTorch, weight decay can also be done automatically inside an optimizer. The parameter `weight_decay`\n",
        "of `optim.SGD` and most other optimizers uses $L^2$ regularization for weight decay. The value of the\n",
        "`weight_decay` parameter is another tunable hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alAVAQ_AR2zG"
      },
      "source": [
        "model = MNISTClassifier()\n",
        "train(model, mnist_train, mnist_val, num_iters=500, weight_decay=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6B7GNP4R2zJ"
      },
      "source": [
        "## Dropout\n",
        "\n",
        "Yet another way to prevent overfitting is to build **many** models, then average\n",
        "their predictions at test time. Each model might have a different set of\n",
        "initial weights.\n",
        "\n",
        "We won't show an example of model averaging here. Instead, we will show another\n",
        "idea that sounds drastically different on the surface.\n",
        "\n",
        "This idea is called **dropout**: we will randomly \"drop out\", \"zero out\", or \"remove\" a portion\n",
        "of neurons from each training iteration.\n",
        "\n",
        "![](imgs/dropout.png)\n",
        "\n",
        "In different iterations of training, we will drop out a different set of neurons.\n",
        "\n",
        "The technique has an effect of preventing weights from being overly dependent on\n",
        "each other: for example for one weight to be unnecessarily large to compensate for\n",
        "another unnecessarily large weight with the opposite sign. Weights are encouraged\n",
        "to be \"more independent\" of one another.\n",
        "\n",
        "During test time though, we will not drop out any neurons; instead we will use\n",
        "the entire set of weights. This means that our training time and test time behaviour\n",
        "of dropout layers are *different*. In the code for the function `train` and `get_accuracy`,\n",
        "we use `model.train()` and `model.eval()` to flag whether we want the model's training behaviour,\n",
        "or test time behaviour.\n",
        "\n",
        "While unintuitive, using all connections is a form\n",
        "of model averaging! We are effectively averaging over many different networks\n",
        "of various connectivity structures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RwPAMLTR2zK"
      },
      "source": [
        "class MNISTClassifierWithDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifierWithDropout, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 50)\n",
        "        self.layer2 = nn.Linear(50, 20)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.dropout1 = nn.Dropout(0.4) # drop out layer with 20% dropped out neuron\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28)\n",
        "        activation1 = F.relu(self.layer1(self.dropout1(flattened)))\n",
        "        activation2 = F.relu(self.layer2(self.dropout2(activation1)))\n",
        "        output = self.layer3(self.dropout3(activation2))\n",
        "        return output\n",
        "\n",
        "model = MNISTClassifierWithDropout()\n",
        "train(model, mnist_train, mnist_val, num_iters=500)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
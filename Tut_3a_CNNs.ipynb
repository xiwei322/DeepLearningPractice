{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6x62xMrvYsy"
      },
      "source": [
        "## Tutorial 3a - Convolutional Neural Networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Mmucb8tjca"
      },
      "source": [
        "### Convolutional Neural Networks\n",
        "\n",
        "In the last lecture we discussed how convolutional neural networks (CNNs) can take advantage of spatial features to improve classification on images. In essence this is achieved by having the network learn kernel parameters to identify lines, edges, corners, colours and other patterns all the way to higher level complexities that can represent objects in the image and strengthen the decision making process.\n",
        "\n",
        "As a result of the spatial features CNNs can handle translational variations in images or simply put, we are able to find objects that are not perfectly centered in the image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdQU6E-YZ-o8"
      },
      "source": [
        "## From ANN to CNN\n",
        "In the example below you'll see that to go from an ANN to a CNN we only need to make a few changes to our architecture. The rest of the code remains the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QjPfFMYc9r5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import torch.optim as optim #for gradient descent\n",
        "\n",
        "torch.manual_seed(1) # set the random seed\n",
        "\n",
        "# obtain data\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "mnist_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_data = list(mnist_data)\n",
        "mnist_train = mnist_data[:4096]\n",
        "mnist_val   = mnist_data[4096:5120]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDmLnmegeccP"
      },
      "source": [
        "### ANN and CNN Architectures\n",
        "Provided is sample code showing the differences between a basic ANN and CNN architectures. Notice that the CNN architecture also contains fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LOeXRJlen1V"
      },
      "outputs": [],
      "source": [
        "class ANN_MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANN_MNISTClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 50)\n",
        "        self.fc2 = nn.Linear(50, 20)\n",
        "        self.fc3 = nn.Linear(20, 10)  \n",
        "\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28)\n",
        "        activation1 = F.relu(self.fc1(flattened))\n",
        "        activation2 = F.relu(self.fc2(activation1))\n",
        "        output = self.fc3(activation2)\n",
        "        return output\n",
        "    \n",
        "    print('Artificial Neural Network Architecture (aka MLP) Done')\n",
        "\n",
        "#Convolutional Neural Network Architecture\n",
        "class CNN_MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_MNISTClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 5, 5) #in_channels, out_chanels, kernel_size\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride \n",
        "        self.conv2 = nn.Conv2d(5, 10, 5) #in_channels, out_chanels, kernel_size\n",
        "        self.fc1 = nn.Linear(160, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 160)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "    print('Convolutional Neural Network Architecture Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sulM0_PKokld"
      },
      "source": [
        "The general formula is this if you are interested: $[(Wâˆ’K+2P)/S]+1$.\n",
        "\n",
        "* $W$ is the input size \n",
        "* $K$ is the Kernel size \n",
        "* $P$ is the padding \n",
        "* $S$ is the stride\n",
        "\n",
        "==============================================================\n",
        "\n",
        "* $28\\times 28$ (1ch) => conv1 => $24\\times24$ (5ch) --- (28-5+1)\n",
        "* $24\\times24$ (5ch) => pool => $12\\times12$ (5ch)\n",
        "* $12\\times12$ (5ch) => conv2 => $8\\times8$ (10ch)\n",
        "* $8\\times8$ (10ch) => pool => $4\\times4$ (10ch)\n",
        "* $4\\times4$ (10ch)  => Flat => $4\\times4\\times10 = 160$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCJBhePhWLiR"
      },
      "source": [
        "![Conv](https://miro.medium.com/max/1050/1*K_OsaLGJ7I8cGlPvvWYJdg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83d_z1QtW7lr"
      },
      "source": [
        "https://cs231n.github.io/convolutional-networks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnwzsoywdg6O"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, train=False):\n",
        "    if train:\n",
        "        data = mnist_train\n",
        "    else:\n",
        "        data = mnist_val\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):\n",
        "        \n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JchuI0fXdj6V"
      },
      "outputs": [],
      "source": [
        "def train(model, data, batch_size=64, num_epochs=1):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "              \n",
        "            out = model(imgs)             # forward pass\n",
        "\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            train_acc.append(get_accuracy(model, train=True)) # compute training accuracy \n",
        "            val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy\n",
        "            n += 1\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YFTuGVyl_wo"
      },
      "source": [
        "### Comparing ANNs and CNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKThfucAgwvI"
      },
      "outputs": [],
      "source": [
        "#proper model\n",
        "print(\"ANN\")\n",
        "model_ANN = ANN_MNISTClassifier()\n",
        "print(model_ANN)\n",
        "train(model_ANN, mnist_train, num_epochs=5)\n",
        "\n",
        "\n",
        "print(\"CNN\")\n",
        "model = CNN_MNISTClassifier()\n",
        "print(model)\n",
        "train(model, mnist_train, num_epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTECqvrkphiq"
      },
      "source": [
        "With 5 epochs selected it can take several minutes to train the network. With the power of GPUs we can greatly reduce the time required and put that to tune our hyperparameters to acheive better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039PX7SFZ0vm"
      },
      "source": [
        "## Enable GPU\n",
        "PyTorch allows you to run the computations on a GPU to speed up the processing. In order to enable GPUs you will need to:\n",
        "1. select GPUs in \"Runtime\" menu, \"change runtime type\".\n",
        "2. setup **model** to work with the cuda\n",
        "3. make sure **image** and **labels** data are stored placed on the GPU\n",
        "\n",
        "An example of this is provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUZybXVsgZ6g"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, train=False):\n",
        "    if train:\n",
        "        data = mnist_train\n",
        "    else:\n",
        "        data = mnist_val\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):\n",
        "        \n",
        "        \n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "        \n",
        "        \n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHdmhKvjgZ6l"
      },
      "outputs": [],
      "source": [
        "def train(model, data, batch_size=64, num_epochs=1):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "          \n",
        "          \n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            #############################################\n",
        "            \n",
        "              \n",
        "            out = model(imgs)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            train_acc.append(get_accuracy(model, train=True)) # compute training accuracy \n",
        "            val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy\n",
        "            n += 1\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nZGQtvlrCuJ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUaUzEZBg4tv"
      },
      "outputs": [],
      "source": [
        "use_cuda = True\n",
        "\n",
        "model = CNN_MNISTClassifier()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "  \n",
        "#proper model\n",
        "train(model, mnist_train, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe7VCsvdVQFc"
      },
      "source": [
        "## Practice to make sure you get the dimensions right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZJQe9kxkZ8g"
      },
      "source": [
        "The general formula is this if you are interested: $[(Wâˆ’K+2P)/S]+1$.\n",
        "\n",
        "* $W$ is the input volume \n",
        "* $K$ is the Kernel size \n",
        "* $P$ is the padding \n",
        "* $S$ is the stride"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NZrImQpOty4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.randn(20, 3, 28, 28) # N(batch size), C(channel), H(height), W(width)\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=7, kernel_size=5, padding=0)\n",
        "print(conv(x).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpvZQSxvPEMh"
      },
      "outputs": [],
      "source": [
        "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "print(pool(x).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiuZ3oSFyc4h"
      },
      "source": [
        "## Visualize Kernels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-l43gl5mFc"
      },
      "source": [
        "Recall what our convolution layer looks like:\n",
        "\n",
        "*self.conv1 = nn.Conv2d(1, 5, 5) #in_channels, out_chanels, kernel_size*\n",
        "\n",
        "There are 5 out channels => 5 kernels, kernel size = 5 and in_channels = 1, hence we're using 5 x 5 kernels. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYM5tuMaim_3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize conv1 kernels (i.e filter)\n",
        "kernels = model.conv1.weight.detach()\n",
        "\n",
        "print(kernels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIsATRGA6rZA"
      },
      "source": [
        "We can also plot the kernels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEG7Z3Jf5lRe"
      },
      "outputs": [],
      "source": [
        "#this line is required if using GPU\n",
        "kernels = kernels.cpu()\n",
        "\n",
        "#display first kernel\n",
        "print(kernels[0][0])\n",
        "\n",
        "#display all five kernels of dimension 5 x 5\n",
        "fig, axarr = plt.subplots(kernels.size(0))\n",
        "for idx in range(kernels.size(0)):\n",
        "    axarr[idx].imshow(kernels[idx][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gDfAbUK3FtB"
      },
      "source": [
        "### Visualize Feature Map\n",
        "We can also apply our kernel to our images to see what kind of features it extracts. In the example we will use a new image, but we could also apply this to one of the images in our training or validation data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAQ4DdOvycIP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal as sg\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "#load image from the internet\n",
        "url = 'https://i.ytimg.com/vi/BqKXHIRwGbs/maxresdefault.jpg'\n",
        "resp = requests.get(url, stream=True).raw\n",
        "img = Image.open(resp)\n",
        "\n",
        "#ensure image is np.array\n",
        "img = np.array(img)\n",
        "\n",
        "#plot original image\n",
        "plt.title(\"Image\")\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "#increase data precision\n",
        "img = img.astype(np.int16)\n",
        "print('Image Max Value:', np.amax(img), 'Image Min Value:', np.amin(img))\n",
        "\n",
        "#convert from colour to grayscale\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])\n",
        "  \n",
        "img_gray = rgb2gray(img)\n",
        "\n",
        "#plot grayscale image\n",
        "plt.title(\"Grayscale Image\")\n",
        "plt.imshow(img_gray, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print (\"\\n\\n########### Conv Outputs ###########\")\n",
        "#select kernel\n",
        "for i in range (0,5):\n",
        "  k = kernels[i][0]\n",
        "\n",
        "  #perform 2d convolution\n",
        "  img_k = sg.convolve(img_gray, k, mode='same')\n",
        "  print (\"Kernel: \", i)\n",
        "  print('Image Max Value:', np.amax(img_k), 'Image Min Value:', np.amin(img_k))\n",
        "\n",
        "  #clipping \n",
        "  #img_k[img_k > 255] = 255\n",
        "  #img_k[img_k < 0] = 0\n",
        "\n",
        "  #Normalizing\n",
        "  img_k = (img_k-img_k.min())/(img_k.max()-img_k.min())*255\n",
        "\n",
        "  print('Image Max Value Normalized:', np.amax(img_k), 'Image Min Value:', np.amin(img_k))\n",
        "\n",
        "  #return to image format\n",
        "  img_k = img_k.astype(np.uint8)\n",
        "\n",
        "  #plot results of convolution\n",
        "  plt.title(\"Feature Map for Specified Kernel\")\n",
        "  plt.imshow(img_k, cmap='gray')\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "S22_APS360_Tut3a_CNNs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
